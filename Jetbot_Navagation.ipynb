{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "objective-parameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda')\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "#import segmentation_models_pytorch as smp\n",
    "from torchvision.transforms import Normalize\n",
    "from math import pi, sin,cos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "czech-planner",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = torch.Tensor([0.485, 0.456, 0.406]).cuda().half()\n",
    "std = torch.Tensor([0.229, 0.224, 0.225]).cuda().half()\n",
    "\n",
    "#normalize = torchvision.transforms.Normalize(mean, std)\n",
    "#normalize_fuc = Normalize(mean, std) \n",
    "def preprocess(image):\n",
    "    image = Image.fromarray(image)\n",
    "    image = transforms.functional.to_tensor(image).to(device).half()\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efficient-basement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best saved checkpoint\n",
    "model = torch.load('./best_model160_5.pth')\n",
    "model = model.cuda().eval().half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fifth-skill",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traitlets\n",
    "import ipywidgets.widgets as widgets\n",
    "import ipywidgets\n",
    "#from fastseg.image import colorize, blend\n",
    "# IPython Libraries for display and widgets\n",
    "import traitlets\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Camera and Motor Interface for JetBot\n",
    "from jetbot import Robot, Camera, bgr8_to_jpeg\n",
    "\n",
    "# Basic Python packages for image annotation\n",
    "from uuid import uuid1\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import datetime\n",
    "import numpy as np\n",
    "#import cv2\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "mtx = np.array([[185.40929109,   0.        , 219.49061385],\n",
    "       [  0.        , 243.56364667, 211.93760043],\n",
    "       [  0.        ,   0.        ,   1.        ]])\n",
    "\n",
    "dist = np.array([[-0.31429013,  0.09988483, -0.00360046, -0.00090223, -0.01470093]])\n",
    "\n",
    "newcameramtx = np.array([[ 39.06088638,   0.        , 285.18778276],\n",
    "       [  0.        ,  60.61566544, 115.67541321],\n",
    "       [  0.        ,   0.        ,   1.        ]])\n",
    "\n",
    "\n",
    "roi = (239, 63, 84, 100)\n",
    "    \n",
    "\n",
    "def xy_points(index, width):\n",
    "    M = cv2.moments(index*1.)\n",
    "    cY = int(M[\"m10\"] / M[\"m00\"])\n",
    "    cX = int(M[\"m01\"] / M[\"m00\"])\n",
    "    if cX < 10:\n",
    "        cX = 10\n",
    "    #if cY < 10:\n",
    "    #    cY = 10\n",
    "    angle = np.arctan2(width/2-cY, width-cX)#*pi#-cX)\n",
    "    return angle, cY, cX\n",
    "\n",
    "\n",
    "def segmentation(image):\n",
    "    #tri = triangle()\n",
    "    #tri = tri[:,:]==1\n",
    "    image = cv2.resize(image, (width,height))\n",
    "    x_tensor = preprocess(image)\n",
    "    mask = model.predict(x_tensor).to(device).half()\n",
    "    mask = (mask.squeeze().cpu().numpy().round())\n",
    "    mask = np.array(mask, dtype = np.uint8)#mask = np.uint8(mask)\n",
    "    mask = mask == 1\n",
    "    #mask = mask*tri\n",
    "    mask = mask[:,:,np.newaxis]\n",
    "    mask1 = np.concatenate([mask,mask,mask], axis =2)\n",
    "    #way Segmentation\n",
    "    index = np.concatenate([mask*128,mask*64,mask*128], axis =2)\n",
    "    #return image*index, mask\n",
    "    return image*mask1, index*1\n",
    "\n",
    "\n",
    "def un_dst(image, width, height):\n",
    "    #Undistortion parameters.\n",
    "    image = cv2.resize(image, (400,400), interpolation = cv2.INTER_AREA)\n",
    "    dst = cv2.undistort(image, mtx, dist, None, newcameramtx)\n",
    "    # crop the image\n",
    "    x,y,w,h = roi\n",
    "    image = dst[y:y+h, x:x+w]\n",
    "    return image#cv2.resize(image, (width, height), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "def show_segmented_view(image,cY,cX):\n",
    "    image = cv2.circle(image, (cY,cX), 8, (0, 255, 0), 3)\n",
    "    image = cv2.circle(image, (int(width / 2), widget_height), 8, (0, 0,255), 3)\n",
    "    image = cv2.line(image, (cY,cX), (int(width / 2), widget_height), (255,0,0), 3)\n",
    "    #image = blend(image, colorized)\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "radical-passion",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = Camera()\n",
    "\n",
    "widget_width = 320#camera.width\n",
    "widget_height = 320#camera.height\n",
    "\n",
    "width, height = 160,160\n",
    "\n",
    "image_widget = widgets.Image(format='jpeg',  width=widget_width, height=widget_height)\n",
    "target_widget = widgets.Image(format='jpeg', width=widget_width, height=widget_height)\n",
    "\n",
    "speed_gain_slider = ipywidgets.FloatSlider(min=0.0, max=2.0, step=0.01, value=0.0, description='speed gain')\n",
    "steering_Pgain_slider = ipywidgets.FloatSlider(min=0.0, max=1.0, step=0.01, value=0.17, description='steering kP')\n",
    "steering_Dgain_slider = ipywidgets.FloatSlider(min=0.0, max=0.5, step=0.01, value=0.30, description='steering kD')\n",
    "steering_Igain_slider = ipywidgets.FloatSlider(min=0.0, max=0.5, step=0.01, value=0.0, description='steering kI')\n",
    "steering_bias_slider = ipywidgets.FloatSlider(min=-0.3, max=0.3, step=0.005, value=0.0, description='steering bias')\n",
    "\n",
    "\n",
    "x_slider = ipywidgets.FloatSlider(min=-1.0, max=1.0, description='x')\n",
    "y_slider = ipywidgets.FloatSlider(min=0, max=1.0, orientation='vertical', description='y')\n",
    "steering_slider = ipywidgets.FloatSlider(min=-1.0, max=1.0, description='steering')\n",
    "left_speed_slider = ipywidgets.FloatSlider(min=0, max=1.0, orientation='vertical', description='left speed')\n",
    "right_speed_slider = ipywidgets.FloatSlider(min=0, max=1.0, orientation='vertical', description='right speed')\n",
    "speed_slider = ipywidgets.FloatSlider(min=0, max=1.0, orientation='vertical', description='speed')\n",
    "direction_point = widgets.widget_float.Tuple\n",
    "\n",
    "\n",
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "northern-jewel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9e19985d3754a6f97072f1ee443f9f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74fb11e65f1242aa8e9a7d8f90724884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatSlider(value=0.253125, description='y', max=1.0, orientation='vertical'), FloatSlider(valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60722f11439149e6ad6bfb19be5bc776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.371875, description='x', max=1.0, min=-1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "353fbcc748094395b75436b5c0ab9ab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=-0.011461142311177713, description='steering', max=1.0, min=-1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28fd0935373342bd8b3090005155cf62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='speed gain', max=2.0, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a806764b0e4b492980e68cf5a11e0d49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.17, description='steering kP', max=1.0, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a0d839a23f84d5cad795ffbc2c9db0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='steering kI', max=0.5, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e676a8115b294d1aba26aed490c7c289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.3, description='steering kD', max=0.5, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ec92fe23fbd45c9af96d1c07e7b775a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='steering bias', max=0.3, min=-0.3, step=0.005)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "angle = 0.0\n",
    "angle_last = 0.0\n",
    "\n",
    "\n",
    "def display_xy(camera_image):\n",
    "    global angle, angle_last\n",
    "    image1 = np.copy(camera_image)\n",
    "    image1 = np.resize(image1,(400,400))\n",
    "    \n",
    "    ## Need to be checked for the channel\n",
    "    image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB)\n",
    "    ############## undistort\n",
    "    image1 = un_dst(image1, width,height)\n",
    "    ###############\n",
    "    image, index1 = segmentation(image1)\n",
    "    #####################\n",
    "    angle, cY, cX = xy_points(np.squeeze(index1[:,:,0]),width)\n",
    "    \n",
    "    x_slider.value = cX/width/2\n",
    "    y_slider.value = cY/height/2\n",
    "\n",
    "    image = show_segmented_view(image,cY,cX)#show_segmented_view(image, direction_point.ValueWidget) \n",
    "    \n",
    "    pid = angle * steering_Pgain_slider.value +  (angle - angle_last)*steering_Dgain_slider.value #+((angle + angle_last)/2)*steering_Igain_slider.value\n",
    "    angle_last = angle\n",
    "    \n",
    "    steering_slider.value = pid + steering_bias_slider.value\n",
    "\n",
    "    robot.left_motor.value = max(min(speed_gain_slider.value + steering_slider.value, 1.0), 0.0)\n",
    "    robot.right_motor.value = max(min(speed_gain_slider.value - steering_slider.value, 1.0), 0.0)    \n",
    "\n",
    "    image = cv2.resize(image, (160,160), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    \n",
    "    jpeg_image = bgr8_to_jpeg(image)\n",
    "    return jpeg_image\n",
    "\n",
    "#time.sleep(3)\n",
    "traitlets.dlink((camera, 'value'), (image_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "traitlets.dlink((camera, 'value'), (target_widget, 'value'), transform=display_xy)\n",
    "\n",
    "display(widgets.HBox([target_widget]))\n",
    "\n",
    "display(ipywidgets.HBox([y_slider,speed_slider, left_speed_slider, right_speed_slider]))\n",
    "display(x_slider, steering_slider)\n",
    "\n",
    "\n",
    "display(speed_gain_slider, steering_Pgain_slider, steering_Igain_slider, steering_Dgain_slider, steering_bias_slider)\n",
    "\n",
    "#direction_point = widgets.widget_float.Tuple\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "subtle-pitch",
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-healing",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
